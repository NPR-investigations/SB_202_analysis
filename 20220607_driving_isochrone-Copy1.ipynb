{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import io\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import geojson\n",
    "from shapely.geometry import shape\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/jhuo/Documents/20220421_WABE_SB202/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-campus",
   "metadata": {},
   "source": [
    "### 20220607 make 5 and 25 minute transit isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-toronto",
   "metadata": {},
   "source": [
    "Steps:<br>\n",
    "1. generate isochrones\n",
    "2. use county boundaries as bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = gpd.read_file('tl_2020_us_county/tl_2020_us_county.shp')\n",
    "GA = boundary[boundary.STATEFP == '13'].copy()\n",
    "GA = GA.to_crs('EPSG:4326')\n",
    "GA1 = GA.rename(columns = {'geometry':'county_boundary'}).iloc[:,[3,17]].copy()\n",
    "GA1 = GA1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "allboxes = pd.read_csv('20220520_jan_21_jan_21_may_22_unified_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "makechrone = allboxes[(allboxes.in_2022 == True) | (allboxes.in_nov_2020 == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "makechrone = makechrone.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/heremaps/here-location-services-python/blob/master/docs/notebooks/isoline_routing_restaurant_search.ipynb\n",
    "os.environ[\"LS_API_KEY\"] = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from here_location_services import LS\n",
    "# from here_map_widget import Map, Marker, GeoJSON, Group\n",
    "from here_location_services.config.isoline_routing_config import (\n",
    "    RANGE_TYPE,\n",
    "    ISOLINE_ROUTING_TRANSPORT_MODE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_API_KEY = os.environ.get(\"LS_API_KEY\")\n",
    "ls = LS(api_key=LS_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_object = datetime.strptime('2022-05-05T14:01:00', '%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driving_iso(df,i):\n",
    "    lat = df.lat.iloc[i]\n",
    "    long = df.long.iloc[i]\n",
    "    \n",
    "    listi = []\n",
    "    for travel_time in [300,1500]:\n",
    "        dicti = {}\n",
    "        result1 = ls.calculate_isoline(\n",
    "                    destination=[lat, long],\n",
    "                    range=str(travel_time),\n",
    "                    arrival_time=datetime_object,\n",
    "                    range_type=RANGE_TYPE.time,\n",
    "                    transport_mode=ISOLINE_ROUTING_TRANSPORT_MODE.car)\n",
    "        data1 = result1.to_geojson()\n",
    "        Polygon = shape(data1['features'][0]['geometry'])\n",
    "        dicti['travel_time'] = travel_time\n",
    "        dicti['lat'] = lat\n",
    "        dicti['long'] = long\n",
    "        dicti['geometry'] = Polygon\n",
    "        listi.append(dicti)\n",
    "    gdf = gpd.GeoDataFrame(listi)\n",
    "    return(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "try1 = get_driving_iso(makechrone,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf = gpd.GeoDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf = alldf.append(try1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in makechrone.index.tolist():\n",
    "    try:\n",
    "        df = get_driving_iso(makechrone,i)\n",
    "        alldf = alldf.append(df)\n",
    "        print (i)\n",
    "    except Exception:\n",
    "        print ('error')\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf1 = alldf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf1['dropbox_point'] = gpd.points_from_xy(alldf1.long, alldf1.lat, crs=\"EPSG:4326\")\n",
    "alldf1pts = alldf1.rename(columns = {'geometry':'isochrone','dropbox_point':'geometry'})\n",
    "alldf1pts.crs = 'EPSG:4326'\n",
    "# find out which county each drop box belongs to\n",
    "alldf2 = gpd.sjoin(alldf1pts, GA, how = 'left', op = 'within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf2[pd.isna(alldf2.COUNTYFP) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf2 = alldf2.drop(['STATEFP', 'COUNTYFP', 'COUNTYNS', 'NAME', 'NAMELSAD', 'LSAD',\n",
    "       'CLASSFP', 'MTFCC', 'CSAFP', 'CBSAFP', 'METDIVFP', 'FUNCSTAT', 'ALAND',\n",
    "       'AWATER', 'INTPTLAT', 'INTPTLON', 'geometry'], axis = 1)\n",
    "alldf2 = alldf2.rename(columns = {'geometry':'drop_box_loc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "GA1 = GA.rename(columns = {'geometry':'county_boundary'}).iloc[:,[3,17]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "GA1 = GA1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-wiring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GA1 = GA.rename(columns = {'geometry':'county_boundary'})[['GEOID','county_boundary']].copy()\n",
    "alldf3 = pd.merge(alldf2, GA1, on = 'GEOID', how = 'outer')\n",
    "alldf3 = alldf3.rename(columns = {'isochrone':'geometry'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf3 = alldf3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_isochrones = gpd.GeoDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(np.arange(0,len(alldf3))):\n",
    "    try:\n",
    "        gdf = gpd.GeoDataFrame(alldf3.iloc[[i]])\n",
    "        gdf.crs ='EPSG:4326'\n",
    "        clipping = gpd.GeoDataFrame([1], geometry=[(alldf3.county_boundary.iloc[i])], crs='EPSG:4326') \n",
    "        clipped = gpd.clip(gdf,clipping)\n",
    "        clipped_isochrones = clipped_isochrones.append(clipped)\n",
    "        print (i)\n",
    "    except Exception:\n",
    "        print('error')\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_isochrones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_isochrones = clipped_isochrones.rename(columns = {'travel_time':'travel_tim'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_file = gpd.read_file('20220521_driving_isochrone_10_15_20_30.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = pd.concat([old_file,clipped_isochrones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = new_file.drop(['index','level_0','index_right'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file.lat = np.round(new_file.lat,6)\n",
    "new_file.long = np.round(new_file.long,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "allboxesyr = allboxes[['lat','long','in_2022','in_nov_2020']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "allboxesyr.lat = np.round(allboxesyr.lat,6)\n",
    "allboxesyr.long = np.round(allboxesyr.long,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file1 = new_file.merge(allboxesyr, on =['lat','long'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "allboxesyr[allboxesyr.lat == 31.292901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-press",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newfile1 = new_file1[~((pd.isna(new_file1.in_2022) == True) & (pd.isna(new_file1.in_nov_2020) == True))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile1.drop('county_boundary', axis = 1).to_file('.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
