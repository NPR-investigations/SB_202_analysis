{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bridal-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import urllib3\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "# from random import randint\n",
    "# from pandas import json_normalize\n",
    "import censusgeocode as cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protective-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/jhuo/Documents/20220421_WABE_SB202/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '2022429_Georgia_Daily_VoterBase/Georgia_Daily_VoterBase.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "voter = pd.read_csv(filename, low_memory = False, error_bad_lines=False, sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up addresses\n",
    "voter['RESIDENCE_STATE'] = 'GA'\n",
    "voter['ZIP5'] =  [x[:5] if pd.isna(x) == False else x for x in voter.RESIDENCE_ZIPCODE ]\n",
    "voter = voter.fillna('')\n",
    "# strip whitespaces\n",
    "cols = voter.select_dtypes(object).columns\n",
    "voter[cols] = voter[cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "voter['st_address'] = [x + ' ' + y for (x,y) in zip(voter.RESIDENCE_HOUSE_NUMBER , voter.RESIDENCE_STREET_NAME)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = voter.iloc[:,[65,12,63,64]].copy().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking out how many of these addresses have already been geocoded\n",
    "res = ['geocode_results/' + x for x in os.listdir(os.getcwd() + '/geocode_results/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterresults = pd.DataFrame()\n",
    "censusresults = pd.DataFrame()\n",
    "censusapiresults = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-orbit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parse files according to different geocoders\n",
    "for file in res:\n",
    "    # R and python outputs files have headers; inherit them\n",
    "    if (('GeoCode' in file) | ('pythongeocode' in file)):\n",
    "        df = pd.read_csv(file)\n",
    "        masterresults = masterresults.append(df)\n",
    "        continue\n",
    "    # census website outputs do not have headers; add them\n",
    "    if 'GeocodeResults' in file:\n",
    "        try:\n",
    "            df = pd.read_csv(file, names =  ['id', 'address','match','matchtype','parsed','coordinate','tigerlineid','side'])\n",
    "            censusresults = censusresults.append(df)\n",
    "        except Exception:\n",
    "            print (file)\n",
    "            continue\n",
    "    else:\n",
    "        df = pd.read_csv(file)\n",
    "        censusapiresults = censusapiresults.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_voter_path = 'Georgia_Daily_VoterBase12.22/Georgia_Daily_VoterBase.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_voter = pd.read_csv(old_voter_path, low_memory = False, error_bad_lines=False, sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up addresses\n",
    "old_voter['RESIDENCE_STATE'] = 'GA'\n",
    "old_voter['ZIP5'] =  [x[:5] if pd.isna(x) == False else x for x in old_voter.RESIDENCE_ZIPCODE ]\n",
    "old_voter = old_voter.fillna('')\n",
    "# strip whitespaces\n",
    "cols = old_voter.select_dtypes(object).columns\n",
    "old_voter[cols] = old_voter[cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "old_voter['st_address'] = [x + ' ' + y for (x,y) in zip(old_voter.RESIDENCE_HOUSE_NUMBER , old_voter.RESIDENCE_STREET_NAME)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_voter['onelineaddress'] = [x + ' ' + y + ' ' + z + ' ' + a + ' ' + b for (x,y,z,a,b) in zip(old_voter.RESIDENCE_HOUSE_NUMBER, old_voter.RESIDENCE_STREET_NAME, old_voter.RESIDENCE_CITY, old_voter.RESIDENCE_STATE, old_voter.ZIP5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_addr = old_voter.iloc[:,[65,12,63,64]].copy().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_addr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "I did some of the geocoding using batch geocoder and some using the api - treating them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch = old_addr.iloc[93137:,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch = old_address_batch.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_addrbatch = np.array_split(old_address_batch, 302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_addrbatch[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-korea",
   "metadata": {},
   "source": [
    "just need to stich up old_address_batch and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "censusresults['split'] = [x.split(',') if pd.isna(x) == False else [np.nan,np.nan] for x in censusresults['coordinate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "censusresults['lat'] = [x[1] for x in censusresults.split]\n",
    "censusresults['long'] = [x[0] for x in censusresults.split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatres = pd.concat([masterresults,censusresults])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatres = concatres.drop(['coordinate','split'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatres = concatres.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(concatres.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "concalatlong = concatres[['id','lat','long']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(concalatlong.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch1 = pd.merge(old_address_batch, concalatlong, left_on ='index', right_on = 'id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "countres = pd.DataFrame(old_address_batch1.groupby('index')['id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "countres[countres.id == 2].head()\n",
    "# these just seem to be on a different level of accuracy, which I guess is ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating those that have been processed by geocoder - some of them did not return a match\n",
    "old_address_batch2 = old_address_batch1[pd.isna(old_address_batch1.id) == False].copy()\n",
    "old_address_batch2 = old_address_batch2.drop(['index','id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-philip",
   "metadata": {},
   "source": [
    "these are the api results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_api = old_addr.iloc[:93138,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_api['onelineaddress'] = [x  + ' ' + z + ' ' + a + ' ' + b for (x,z,a,b) in zip(old_address_api.st_address, old_address_api.RESIDENCE_CITY, old_address_api.RESIDENCE_STATE, old_address_api.ZIP5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_api1 = pd.merge(old_address_api,censusapiresults, left_on = 'onelineaddress', right_on = 'input', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_api2 = old_address_api1[pd.isna(old_address_api1.input) == False].copy()[['st_address','RESIDENCE_CITY','RESIDENCE_STATE','ZIP5','coordinates']].copy().drop_duplicates()\n",
    "old_address_api2['lat'] = [x.split(':')[2].split('}')[0] for x in old_address_api2.coordinates]\n",
    "old_address_api2['long'] = [x.split(':')[1].split(',')[0] for x in old_address_api2.coordinates]\n",
    "old_address_api2.lat = old_address_api2.lat.str.strip()\n",
    "old_address_api2.long = old_address_api2.long.str.strip()\n",
    "old_address_api2 = old_address_api2.drop('coordinates', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-stuart",
   "metadata": {},
   "source": [
    "concacenating the two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatresults = pd.concat([old_address_api2,old_address_batch2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_batch2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_address_api2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 10% of these results were passed thru and not geocoded.\n",
    "len(concatresults[pd.isna(concatresults.lat) == True])/len(concatresults[pd.isna(concatresults.lat) == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatresults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatresults['processed'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-cooking",
   "metadata": {},
   "source": [
    "merging the old voter file with the new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "addrmerge = pd.merge(addresses, concatresults, on = ['st_address','RESIDENCE_CITY','RESIDENCE_STATE','ZIP5'], how = 'left')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "realistic-proposal",
   "metadata": {},
   "source": [
    "addresses.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "radical-austin",
   "metadata": {},
   "source": [
    "concatresults.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "under-novel",
   "metadata": {},
   "source": [
    "to_geocode = addrmerge[pd.isna(addrmerge.processed) == True].copy().reset_index()[['st_address','RESIDENCE_CITY','RESIDENCE_STATE','ZIP5']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "considered-environment",
   "metadata": {},
   "source": [
    "addrmerge[pd.isna(addrmerge.processed) == True].info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "institutional-camera",
   "metadata": {},
   "source": [
    "addrmerge[pd.isna(addrmerge.processed) == False].info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "pretty-constraint",
   "metadata": {},
   "source": [
    "to_geocode.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "social-placement",
   "metadata": {},
   "source": [
    "batchcount = len(addrmerge[pd.isna(addrmerge.processed) == True])//10000+1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "joined-armstrong",
   "metadata": {},
   "source": [
    "batchcount"
   ]
  },
  {
   "cell_type": "raw",
   "id": "guilty-token",
   "metadata": {},
   "source": [
    "addrbatch = np.array_split(to_geocode, batchcount)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "failing-population",
   "metadata": {},
   "source": [
    "addrbatch[0].info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "brief-shopper",
   "metadata": {},
   "source": [
    "for batch in addrbatch:\n",
    "    order = next(i for i, j in enumerate(addrbatch) if j is batch) \n",
    "    filepath = 'batch_geocoding/20220502_batch_' + str(order) + '_of_' + str(batchcount) + '.csv'\n",
    "    batch.to_csv(filepath, header = False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "catholic-mobile",
   "metadata": {},
   "source": [
    "pathlist = ['batch_geocoding/' + x for x in os.listdir(os.getcwd() + '/batch_geocoding/')]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "protective-chemical",
   "metadata": {},
   "source": [
    "pathlist1 = [x for x in pathlist if '20220502' in x]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "varying-organizer",
   "metadata": {},
   "source": [
    "for path in pathlist1:\n",
    "    try:\n",
    "        name = path.split('/')[-1].split('.')[0]\n",
    "        newname = 'pythongeocode_' + name\n",
    "        result = cg.addressbatch(path, returntype = 'locations')\n",
    "        resultdf = pd.DataFrame(result)\n",
    "        respath = 'geocode_results/' + newname + '.csv'\n",
    "        resultdf.to_csv(respath)\n",
    "        print (path)\n",
    "        print(pathlist1.index(path))\n",
    "    except Exception:\n",
    "        print ('error')\n",
    "        print(pathlist1.index(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
